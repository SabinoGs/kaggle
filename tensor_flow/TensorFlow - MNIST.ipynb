{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import pathlib\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-9ba06afd791b>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/gustavo/Envs/machine/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/gustavo/Envs/machine/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting mnist/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/gustavo/Envs/machine/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting mnist/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/gustavo/Envs/machine/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting mnist/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/gustavo/Envs/machine/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('mnist/', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregando as imagens\n",
    "\n",
    "As imagens estão representadas como um array único. Isso significa que a imagem está como um array de 784 dimensões (28x28). Imagens são representadas como matrizes, geralmente. Então, em alguns algoritmos, há a necessidade de dar um reshape nela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 784) (55000, 10)\n",
      "(10000, 784) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "x_train = mnist.train.images\n",
    "y_train = mnist.train.labels\n",
    "print(x_train.shape, y_train.shape)\n",
    "\n",
    "x_test = mnist.test.images\n",
    "y_test = mnist.test.labels\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**O matplotlib não irá aceitar um array de 784 dimensões como uma imagem. Por isso, tem que dar o reshape**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb16f83c860>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+j+DJMloEjk5BgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Classe: {}'.format(np.argmax(y_train[5])))\n",
    "plt.imshow(x_train[5].reshape(28,28), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construção da arquitetura da Rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição do input. O numero de neuronios do input é o tamanho do array\n",
    "NEURONIOS_INPUT = x_train.shape[1]\n",
    "\n",
    "\n",
    "# Definição do numero de hidden Layers. Para esse exemplo, serão utilizados 3 hidden layers\n",
    "# Utilizarei o mesmo nome do layer, pois eles serão entrada um do outro\n",
    "NEURONIOS_HIDDEN = int((x_train.shape[1]+y_train.shape[1])/2)\n",
    "\n",
    "# Definição do numero de neuronios da camada de saída. \n",
    "# Os neuronios dessa camada correspondem as classes possíveis. \n",
    "\n",
    "NEURONIOS_OUTPUT = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rede: 784 -> 397 -> 397 -> 397 -> 10\n"
     ]
    }
   ],
   "source": [
    "print(\"Rede: {} -> {} -> {} -> {} -> {}\".format(\n",
    "    NEURONIOS_INPUT,\n",
    "    NEURONIOS_HIDDEN,\n",
    "    NEURONIOS_HIDDEN,\n",
    "    NEURONIOS_HIDDEN,\n",
    "    NEURONIOS_OUTPUT\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definindo numero de camadas da rede\n",
    "\n",
    "TODO: Tentativa de identificar o numero de camadas da rede para criar um loop que inicializa os pesos e bias da rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERO_HIDDEN_LAYERS = 3\n",
    "\n",
    "# O total de layers dessa rede, nessa arquitetura (DenseNN), é 1 input layer\n",
    "# 1 output layer e N hidden layers. Por isso, tem-se que o numero total de layers é:\n",
    "\n",
    "TOTAL_LAYES = NUMERO_HIDDEN_LAYERS + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando os pesos e bias da rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pesos = {\n",
    "    'oculta1': tf.Variable(tf.random_normal([NEURONIOS_INPUT, NEURONIOS_HIDDEN])),\n",
    "    'oculta2': tf.Variable(tf.random_normal([NEURONIOS_HIDDEN, NEURONIOS_HIDDEN])),\n",
    "    'oculta3':tf.Variable(tf.random_normal([NEURONIOS_HIDDEN, NEURONIOS_HIDDEN])),\n",
    "    'saida':  tf.Variable(tf.random_normal([NEURONIOS_HIDDEN, NEURONIOS_OUTPUT]))\n",
    "}\n",
    "\n",
    "bias = {\n",
    "    'oculta1': tf.Variable(tf.random_normal([NEURONIOS_HIDDEN])),\n",
    "    'oculta2': tf.Variable(tf.random_normal([NEURONIOS_HIDDEN])),\n",
    "    'oculta3':tf.Variable(tf.random_normal([NEURONIOS_HIDDEN])),\n",
    "    'saida':  tf.Variable(tf.random_normal([NEURONIOS_OUTPUT]))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição dos placeholders para a nossa rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "xph = tf.placeholder(dtype=tf.float32, shape=[None, NEURONIOS_INPUT])\n",
    "yph = tf.placeholder(dtype=tf.float32, shape=[None, NEURONIOS_OUTPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição das funções de ativação\n",
    "\n",
    "Lembre-se que não é realizado essa operação para a `camada de input`. Os valores da camada de input são os próprios inputs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(inputs, pesos, bias):\n",
    "\n",
    "    valores_camada_oculta = tf.nn.relu(\n",
    "        tf.add(\n",
    "            tf.matmul(inputs, pesos['oculta1']), #camada 1\n",
    "            bias['oculta1'])\n",
    "    )\n",
    "\n",
    "    valores_camada_oculta = tf.nn.relu(\n",
    "        tf.add(\n",
    "            tf.matmul(valores_camada_oculta, pesos['oculta2']), #camada 2\n",
    "            bias['oculta2'])\n",
    "    )\n",
    "    valores_camada_oculta = tf.nn.relu(\n",
    "        tf.add(\n",
    "            tf.matmul(valores_camada_oculta, pesos['oculta3']), #camada 3\n",
    "            bias['oculta3'])\n",
    "    )\n",
    "\n",
    "    valores_camada_saida = tf.add(\n",
    "            tf.matmul(valores_camada_oculta, pesos['saida']),  # saida\n",
    "            bias['saida'])\n",
    "    \n",
    "    \n",
    "    return valores_camada_saida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = mlp(xph, pesos, bias)\n",
    "erro = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=modelo, labels=yph))\n",
    "otimizador = tf.train.AdamOptimizer().minimize(erro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoca: 0 - Erro: 35660.25390625\n",
      "Epoca: 100 - Erro: 2843.841796875\n",
      "Epoca: 200 - Erro: 1508.28662109375\n",
      "Epoca: 300 - Erro: 1394.343505859375\n",
      "Epoca: 400 - Erro: 863.279052734375\n",
      "Epoca: 500 - Erro: 1472.333251953125\n",
      "Epoca: 600 - Erro: 1097.703857421875\n",
      "Epoca: 700 - Erro: 515.0111694335938\n",
      "Epoca: 800 - Erro: 701.1586303710938\n",
      "Epoca: 900 - Erro: 866.971435546875\n",
      "Epoca: 1000 - Erro: 384.2241516113281\n",
      "Epoca: 1100 - Erro: 669.527099609375\n",
      "Epoca: 1200 - Erro: 290.841064453125\n",
      "Epoca: 1300 - Erro: 442.1612548828125\n",
      "Epoca: 1400 - Erro: 90.76585388183594\n",
      "Epoca: 1500 - Erro: 121.48046875\n",
      "Epoca: 1600 - Erro: 270.4407043457031\n",
      "Epoca: 1700 - Erro: 184.67959594726562\n",
      "Epoca: 1800 - Erro: 243.09967041015625\n",
      "Epoca: 1900 - Erro: 48.79304122924805\n",
      "Epoca: 2000 - Erro: 196.09963989257812\n"
     ]
    }
   ],
   "source": [
    "EPOCAS = 6000\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # No treinamento da rede, percorreremos todos os Registros disponíveis\n",
    "    # em cada uma das épocas! Então, se o dado tiver 100k exemplos,\n",
    "    # o codigo abaixo percorrerá 100k exemplos N vezes.\n",
    "    for epoca in range(EPOCAS):\n",
    "        \n",
    "        # Entretando, calculamos o erro da rede a cada 128 registros\n",
    "        x_batch, y_batch = mnist.train.next_batch(128)\n",
    "        _, custo = sess.run([otimizador, erro], feed_dict={xph: x_batch, yph: y_batch})\n",
    "        \n",
    "        if epoca%100 == 0:\n",
    "            print('Epoca: {} - Erro: {}'.format(epoca, custo))\n",
    "    \n",
    "    # Dou um sess.run nos pesos e bias e atribuo o resultado para duas variaveis\n",
    "    # Assim, posso utilizar essas variaveis para fazer minhas predições\n",
    "    w, b = sess.run([pesos, bias]) \n",
    "    print('Treinamento terminado')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualização dos pesos e bias dessa rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    previsoes =  tf.nn.softmax(mlp(xph, w, b))\n",
    "    previsao = sess.run(previsoes, feed_dict={xph: x_test})\n",
    "    previsao = tf.argmax(previsao, axis=1)\n",
    "    previsao = sess.run(previsao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsao"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
