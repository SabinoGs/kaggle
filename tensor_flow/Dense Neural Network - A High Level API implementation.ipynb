{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from pprint import pprint as pp\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNN():\n",
    "    def __init__(self, input_layer, hidden_layers, output_layer):\n",
    "        if not isinstance(hidden_layers, list):\n",
    "            raise TypeError(\"hidden_layers must be a list\")\n",
    "        \n",
    "        self.input = input_layer\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.output_layer = output_layer\n",
    "        \n",
    "        self._inter = hidden.copy()\n",
    "        self._inter.insert(0, inputs)\n",
    "        self._inter.append(output)\n",
    "\n",
    "    @property\n",
    "    def weights(self):\n",
    "        RANGE = range(len(self._inter)-1)\n",
    "        return {ATUAL:tf.Variable(tf.random_normal([self._inter[ATUAL], self._inter[ATUAL+1]])) for ATUAL in RANGE}\n",
    "    \n",
    "    @property\n",
    "    def bias(self):\n",
    "        RANGE = range(len(self._inter)-1)\n",
    "        return {ATUAL:tf.Variable(tf.random_normal([self._inter[ATUAL+1]])) for ATUAL in RANGE}\n",
    "    \n",
    "\n",
    "    def predict(self, data):\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def train(self, inputs, labels):\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def _architecture(self, inputs):\n",
    "        RANGE = range(len(self._inter[1:-1]))\n",
    "        \n",
    "        LAST_WEIGHT_INDEX = None\n",
    "        \n",
    "        #input layer initialization\n",
    "        layer = tf.nn.relu(\n",
    "            tf.add(\n",
    "                tf.matmul(inputs, self.weights[0]),\n",
    "                self.bias[0]\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        #Hidden layers initialization\n",
    "        for index in RANGE:\n",
    "            layer =  tf.nn.relu(\n",
    "                tf.add(\n",
    "                    tf.matmul(layer, self.weights[index]),\n",
    "                    self.bias[index]\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            LAST_WEIGHT_INDEX = index\n",
    "        \n",
    "        # output layer initialization\n",
    "        layer = tf.add(\n",
    "            tf.matmul(layer, self.weigths[LAST_WEIGHT_INDEX])\n",
    "        )\n",
    "        \n",
    "        return layer\n",
    "        \n",
    "    def erro():\n",
    "        erro = tf.reduce_mean(\n",
    "            tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "                logits=self._architecture,\n",
    "                labels='NAO IMPLEMENTADO'\n",
    "            )\n",
    "        )\n",
    "        raise NotImplementedError()\n",
    "        return erro\n",
    "    \n",
    "    def optimizer():\n",
    "        return tf.train.AdamOptimizer().minimize(self.erro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = DenseNN(10, [5,5,5], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = 10\n",
    "hidden = [5,5,5,10]\n",
    "output = 10\n",
    "inter = hidden.copy() \n",
    "inter.insert(0, inputs), inter.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 5, 5, 5, 10, 10]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10 5\n",
      "1 5 5\n",
      "2 5 5\n",
      "3 5 10\n",
      "4 10 10\n",
      "{0: array([[0.15721796, 0.12340868, 0.40907319, 0.62090904, 0.4452194 ],\n",
      "       [0.23334097, 0.23005272, 0.95967143, 0.47364257, 0.39531376],\n",
      "       [0.37822719, 0.13711763, 0.10016261, 0.65106714, 0.46273722],\n",
      "       [0.37235629, 0.93092263, 0.71999094, 0.74731267, 0.14858628],\n",
      "       [0.11730925, 0.9053409 , 0.94006354, 0.54793734, 0.10009021],\n",
      "       [0.59189608, 0.88889832, 0.64987489, 0.632531  , 0.5538611 ],\n",
      "       [0.19127161, 0.82754906, 0.45235968, 0.72306472, 0.74171494],\n",
      "       [0.16131402, 0.89046306, 0.020176  , 0.09688121, 0.74204831],\n",
      "       [0.16454939, 0.98246548, 0.88668587, 0.70562988, 0.69127944],\n",
      "       [0.23820468, 0.05789764, 0.98470313, 0.6151788 , 0.71366018]]),\n",
      " 1: array([[0.35410671, 0.93444044, 0.00823856, 0.15449388, 0.05002646],\n",
      "       [0.09849964, 0.81495931, 0.00414914, 0.65117938, 0.75987866],\n",
      "       [0.43878436, 0.1803109 , 0.25820124, 0.79538901, 0.97034394],\n",
      "       [0.47128529, 0.36238974, 0.15677658, 0.14191943, 0.88465704],\n",
      "       [0.24335074, 0.92994046, 0.52805753, 0.10643896, 0.23352947]]),\n",
      " 2: array([[0.21837075, 0.31709117, 0.72034586, 0.4640212 , 0.62869323],\n",
      "       [0.70304031, 0.19253626, 0.87362935, 0.06977007, 0.81681162],\n",
      "       [0.04268588, 0.46759842, 0.68366023, 0.05075759, 0.47132715],\n",
      "       [0.99227732, 0.0157564 , 0.5776823 , 0.96328461, 0.9730727 ],\n",
      "       [0.25344341, 0.7367257 , 0.569561  , 0.7659192 , 0.13715581]]),\n",
      " 3: array([[0.87908038, 0.90928606, 0.2794378 , 0.26431659, 0.32767498,\n",
      "        0.68896539, 0.41115609, 0.39108478, 0.86567886, 0.64632607],\n",
      "       [0.43024253, 0.89998076, 0.02573633, 0.32623191, 0.61717975,\n",
      "        0.26919973, 0.53318674, 0.03750297, 0.49437416, 0.25940703],\n",
      "       [0.08373401, 0.57386563, 0.70401143, 0.93394567, 0.89827844,\n",
      "        0.25317027, 0.02892208, 0.61039803, 0.82635634, 0.73980984],\n",
      "       [0.7160301 , 0.46697506, 0.27480532, 0.70664448, 0.74328859,\n",
      "        0.49160113, 0.68440761, 0.91792055, 0.33383196, 0.87504895],\n",
      "       [0.47018734, 0.05996734, 0.0500625 , 0.3852854 , 0.13284982,\n",
      "        0.24117589, 0.22215869, 0.61755114, 0.83758704, 0.79220835]]),\n",
      " 4: array([[1.93504687e-01, 6.08255244e-01, 4.09565763e-01, 2.66130939e-01,\n",
      "        7.91048144e-01, 4.85353724e-01, 5.99705327e-04, 7.94983470e-01,\n",
      "        2.24243117e-01, 4.25271885e-02],\n",
      "       [4.21548711e-01, 8.51977942e-01, 8.25044918e-01, 4.72648852e-01,\n",
      "        2.61809846e-01, 8.38074083e-01, 5.91301180e-01, 2.83574407e-01,\n",
      "        6.93877592e-01, 5.73721545e-01],\n",
      "       [5.60396564e-01, 8.31925745e-01, 8.96220574e-01, 3.99415298e-01,\n",
      "        9.31478743e-01, 5.33984601e-01, 8.96205287e-01, 8.38833441e-01,\n",
      "        9.19253196e-01, 3.13742107e-01],\n",
      "       [5.07960318e-02, 8.39266534e-01, 3.75068518e-01, 3.43042335e-02,\n",
      "        6.62144252e-01, 4.22196371e-01, 2.60520825e-01, 1.41595515e-01,\n",
      "        9.98617061e-01, 5.23965105e-01],\n",
      "       [8.09537658e-01, 2.00950267e-01, 3.98012721e-02, 4.74095228e-01,\n",
      "        8.13976501e-01, 3.48302332e-01, 1.00329705e-01, 3.57953929e-01,\n",
      "        4.07235315e-01, 6.96845193e-01],\n",
      "       [7.89101595e-01, 6.40788975e-02, 3.60877849e-01, 6.47758890e-01,\n",
      "        9.85658108e-01, 6.12762308e-01, 7.73646977e-01, 9.10287281e-01,\n",
      "        3.59693999e-01, 4.89266675e-01],\n",
      "       [6.09666121e-01, 2.65229259e-01, 5.01057651e-01, 4.30823807e-01,\n",
      "        8.69308056e-01, 5.65752239e-01, 2.74534166e-01, 1.20176824e-01,\n",
      "        1.14856011e-01, 9.00906025e-01],\n",
      "       [8.45562624e-02, 3.46831596e-01, 5.70569438e-01, 1.34390846e-01,\n",
      "        5.27496602e-03, 1.22422037e-01, 6.56014126e-01, 6.81250572e-01,\n",
      "        9.16408777e-02, 1.33939472e-01],\n",
      "       [8.58864474e-01, 8.56341139e-01, 4.05074331e-01, 1.70839261e-01,\n",
      "        5.23687978e-01, 1.49181427e-01, 2.22796072e-01, 4.42711433e-01,\n",
      "        9.74981866e-01, 8.55816756e-01],\n",
      "       [4.66761408e-01, 2.89046746e-01, 6.84393098e-01, 8.29395291e-01,\n",
      "        6.57841648e-01, 8.96152393e-01, 2.37572414e-01, 1.83266516e-01,\n",
      "        2.18684476e-01, 3.88158271e-01]])}\n",
      "{0: array([0.64885167, 0.29692578, 0.9474843 , 0.70571944, 0.38052128]),\n",
      " 1: array([0.22068612, 0.52193637, 0.84806726, 0.24655846, 0.36217089]),\n",
      " 2: array([0.98622757, 0.85769144, 0.00705472, 0.71467339, 0.73308002]),\n",
      " 3: array([0.23671829, 0.57849145, 0.65136566, 0.5576161 , 0.08642328,\n",
      "       0.12347699, 0.31880792, 0.38001191, 0.12681508, 0.02933312]),\n",
      " 4: array([0.485313  , 0.56694149, 0.12592069, 0.24891954, 0.31301485,\n",
      "       0.07361426, 0.75558611, 0.04583017, 0.30709997, 0.51551289])}\n"
     ]
    }
   ],
   "source": [
    "RANGE_INTERACAO = len(inter)-1\n",
    "\n",
    "\n",
    "weights = dict()\n",
    "bias = dict()\n",
    "\n",
    "for layer_atual in range(RANGE_INTERACAO):\n",
    "    PROXIMO_LAYER = layer_atual + 1\n",
    "    print(layer_atual, inter[layer_atual], inter[PROXIMO_LAYER])\n",
    "    weights[layer_atual] = np.random.rand(inter[layer_atual],inter[PROXIMO_LAYER])\n",
    "    bias[layer_atual] = np.random.rand(inter[PROXIMO_LAYER])\n",
    "\n",
    "    \n",
    "pp(weights)\n",
    "pp(bias)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
