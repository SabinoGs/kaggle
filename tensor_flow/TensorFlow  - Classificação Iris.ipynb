{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gustavo/Envs/machine/lib/python3.5/site-packages/sklearn/preprocessing/_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/gustavo/Envs/machine/lib/python3.5/site-packages/sklearn/preprocessing/_encoders.py:390: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "onehot = OneHotEncoder(categorical_features=[0])\n",
    "y = onehot.fit_transform(y.reshape(-1,1))\n",
    "y = y.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuronios_input = X.shape[1]\n",
    "neuronios_output = y.shape[1]\n",
    "neuronios_oculta =  np.ceil((X.shape[1]+y.shape[1])/2)\n",
    "neuronios_oculta = np.int32(neuronios_oculta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pesos = {\n",
    "    'oculta':tf.Variable(\n",
    "        tf.random_normal([neuronios_input, neuronios_oculta]), dtype=tf.float32),\n",
    "    'saida': tf.Variable(\n",
    "        tf.random_normal([neuronios_oculta, neuronios_output]), dtype=tf.float32) \n",
    "}\n",
    "\n",
    "bias = {\n",
    "    'oculta':tf.Variable(\n",
    "        tf.random_normal([neuronios_oculta])),\n",
    "    'saida': tf.Variable(\n",
    "        tf.random_normal([neuronios_output])) \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Qualquer numero de observações, mas Tem o numero de inputs definido antes\n",
    "xph = tf.placeholder(dtype=tf.float32, shape=[None, neuronios_input])\n",
    "\n",
    "# qualquer numero de observações, mas tem 3 saídas por causa do OnehotEncoder\n",
    "# Essa rede tem 3 saídas. São equivalentes as probabilidades de cada classe\n",
    "yph = tf.placeholder(dtype=tf.float32, shape=[None, neuronios_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilayer_perceptron(inputs, weights, bias):\n",
    "    # multiplicacao dos pesos pelas features\n",
    "    valores_camada_oculta = tf.matmul(inputs, weights['oculta'])\n",
    "    \n",
    "    #adição do bias\n",
    "    valores_camada_oculta = tf.add(valores_camada_oculta, bias['oculta'])\n",
    "    \n",
    "    #Função de ativacao\n",
    "    valores_camada_oculta = tf.nn.relu(valores_camada_oculta)\n",
    "    \n",
    "    #mesmo processo anterior.\n",
    "    valores_camada_saida = tf.matmul(valores_camada_oculta, weights['saida'])\n",
    "    valores_camada_saida = tf.add(valores_camada_saida, bias['saida'])\n",
    "#     valores_camada_saida = tf.nn.softmax(valores_camada_saida)\n",
    "    \n",
    "    return valores_camada_saida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = multilayer_perceptron(xph, pesos, bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição do erro\n",
    "\n",
    "erro  = tf.nn.softmax_cross_entropy_with_logits_v2(logits=modelo, labels=yph)\n",
    "erro = tf.reduce_mean(erro)\n",
    "otimizador = tf.train.AdamOptimizer().minimize(erro)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoca:  0  erro:  10.636483473437172\n",
      "Epoca:  500  erro:  0.0664040577331824\n",
      "Epoca:  1000  erro:  0.03971855766576482\n",
      "Epoca:  1500  erro:  0.03401894936216975\n",
      "Epoca:  2000  erro:  0.032239870507851265\n",
      "Epoca:  2500  erro:  0.03139297587346894\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 8\n",
    "TOTAL_ITERACOES = int(len(X_train)/BATCH_SIZE)\n",
    "EPOCAS = 3000\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoca in range(EPOCAS):\n",
    "        erro_medio = 0.0\n",
    "        \n",
    "        for i in range(TOTAL_ITERACOES):\n",
    "            x = X_train[BATCH_SIZE*i:BATCH_SIZE*(i+1)]\n",
    "            y = y_train[BATCH_SIZE*i:BATCH_SIZE*(i+1)]\n",
    "            _, custo = sess.run([otimizador, erro], feed_dict={xph:x, yph:y})\n",
    "            erro_medio += custo/TOTAL_ITERACOES\n",
    "        if epoca % 500 == 0:\n",
    "            print(\"Epoca: \", epoca, \" erro: \", erro_medio)\n",
    "    pesos_finais, bias_final = sess.run([pesos, bias])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'saida': array([[  0.21316461,  -1.0615246 ,  -0.5832064 ],\n",
      "       [  4.2961926 ,   1.3000625 , -11.312548  ],\n",
      "       [ -9.123332  ,   0.06577493,   0.9042644 ],\n",
      "       [  0.23410052,   2.1235445 ,  -5.2911305 ]], dtype=float32), 'oculta': array([[ 0.52425224, -1.9160359 ,  0.9959063 ,  0.01090503],\n",
      "       [-0.36845785,  1.6150159 , -1.2740028 ,  0.06687524],\n",
      "       [-1.341526  , -1.1911432 ,  2.0890374 , -1.1061895 ],\n",
      "       [ 0.8445673 , -1.9278212 ,  2.908283  , -1.2803642 ]],\n",
      "      dtype=float32)} {'saida': array([0.6012882 , 0.28831527, 0.7959783 ], dtype=float32), 'oculta': array([-0.7667937,  2.7576663,  2.293447 ,  2.217557 ], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "print(pesos_finais, bias_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-17-14a71943f690>:13: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `argmax` instead\n"
     ]
    }
   ],
   "source": [
    "# previsão\n",
    "\n",
    "previsao_teste = multilayer_perceptron(xph, pesos_finais, bias_final)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    prev = sess.run(previsao_teste, feed_dict={xph: X_test, yph:y_test})\n",
    "    #Aplicação da função de probabilidde\n",
    "    prev = sess.run(tf.nn.softmax(prev))\n",
    "    \n",
    "    #Pegando qual coluna tem o valor mais alto, pois, o indice dessa coluna\n",
    "    # indica qual é a categoria da previsão. (Lembre-se do OneHotEncoder definido antes)\n",
    "    prev = sess.run(tf.arg_max(prev, 1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 2 0 0 2 2 1 0 2 1 0 1 2 2 0 1 0 0 1 1 2 1 0 2 1 2 0 2 2 2 0 2 2 2 1 2\n",
      " 1]\n",
      "[1 1 2 0 0 2 2 1 0 2 1 0 2 2 2 0 1 0 0 1 1 2 1 0 2 1 2 0 2 2 1 0 2 2 2 1 2\n",
      " 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       0.92      0.92      0.92        12\n",
      "           2       0.94      0.94      0.94        16\n",
      "\n",
      "   micro avg       0.95      0.95      0.95        38\n",
      "   macro avg       0.95      0.95      0.95        38\n",
      "weighted avg       0.95      0.95      0.95        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prev)\n",
    "print(np.argmax(y_test, 1))\n",
    "\n",
    "\n",
    "print(classification_report(np.argmax(y_test, 1), prev))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
